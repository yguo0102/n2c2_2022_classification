{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7161a060",
   "metadata": {},
   "source": [
    "# Data preprocess\n",
    "\n",
    "## prepare data for event classification\n",
    "The original released data contained a list of `.txt` and `.ann` files, where the `.txt` files are the unstructured clinical notes, and the `.ann` files are annotations including medication entries, event class, and context class.\n",
    "For event classification, the first step was to reformat all these files into a csv file consisting of three columns: `file`, `text`, and `label`. The `file` column is the combined ID for the clinical note, `text` is the chuncked text from the note, and `label` is the groundtruth annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c591ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mendelai-brat-parser in /home/yguo262/.local/lib/python3.6/site-packages (0.0.11)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/rh/rh-python36/root/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mendelai-brat-parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60b5b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all: 6196\n",
      "all: 1033\n",
      "all: 1764\n"
     ]
    }
   ],
   "source": [
    "!rm -r  n2c2_data/*processed\n",
    "!python n2c2_code/extract_data_fixed_len.py n2c2_data/raw/train n2c2_data/train_processed n2c2_data/train.csv\n",
    "!python n2c2_code/extract_data_fixed_len.py n2c2_data/raw/dev n2c2_data/dev_processed n2c2_data/dev.csv\n",
    "!python n2c2_code/extract_data_fixed_len.py n2c2_data/raw/test n2c2_data/test_processed n2c2_data/test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752da61",
   "metadata": {},
   "source": [
    "For event classification, the data set looks like below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba7ac3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/280-03_T2</td>\n",
       "      <td>no shortness of breath. She does get occasiona...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/280-03_T3</td>\n",
       "      <td>She does get occasional abdominal pulsations. ...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/280-03_T4</td>\n",
       "      <td>pulsations. She does get epigastric discomfort...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/280-03_T5</td>\n",
       "      <td>discomfort. Current medications include ranola...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/280-03_T6</td>\n",
       "      <td>mg twice daily, aspirin 325 mg once daily, Pla...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6191</th>\n",
       "      <td>/289-02_T8</td>\n",
       "      <td>mainly ocular. Prior Raynaud's syndrome. Recom...</td>\n",
       "      <td>Disposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>/289-02_T9</td>\n",
       "      <td>days when he had a couple of minor spells. Med...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193</th>\n",
       "      <td>/289-02_T10</td>\n",
       "      <td>he had a couple of minor spells. Medications: ...</td>\n",
       "      <td>NoDisposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6194</th>\n",
       "      <td>/289-02_T11</td>\n",
       "      <td>testing correlating well with a slight increas...</td>\n",
       "      <td>Disposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6195</th>\n",
       "      <td>/289-02_T12</td>\n",
       "      <td>VF arrest and revascularization. Myasthenia, m...</td>\n",
       "      <td>Disposition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6196 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  \\\n",
       "0      /280-03_T2  no shortness of breath. She does get occasiona...   \n",
       "1      /280-03_T3  She does get occasional abdominal pulsations. ...   \n",
       "2      /280-03_T4  pulsations. She does get epigastric discomfort...   \n",
       "3      /280-03_T5  discomfort. Current medications include ranola...   \n",
       "4      /280-03_T6  mg twice daily, aspirin 325 mg once daily, Pla...   \n",
       "...           ...                                                ...   \n",
       "6191   /289-02_T8  mainly ocular. Prior Raynaud's syndrome. Recom...   \n",
       "6192   /289-02_T9  days when he had a couple of minor spells. Med...   \n",
       "6193  /289-02_T10  he had a couple of minor spells. Medications: ...   \n",
       "6194  /289-02_T11  testing correlating well with a slight increas...   \n",
       "6195  /289-02_T12  VF arrest and revascularization. Myasthenia, m...   \n",
       "\n",
       "              label  \n",
       "0     NoDisposition  \n",
       "1     NoDisposition  \n",
       "2     NoDisposition  \n",
       "3     NoDisposition  \n",
       "4     NoDisposition  \n",
       "...             ...  \n",
       "6191    Disposition  \n",
       "6192  NoDisposition  \n",
       "6193  NoDisposition  \n",
       "6194    Disposition  \n",
       "6195    Disposition  \n",
       "\n",
       "[6196 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('n2c2_data/train.csv', usecols=['file', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a9cfd",
   "metadata": {},
   "source": [
    "## prepare data for context classification\n",
    "For context classification, we used the same data splits as event classification. There are 5 types of context classification subtasks: `Action`, `Negation`, `Temporality`, `Certainty`, and `Actor`. For each type, we create a folder with `train.csv`, `dev.csv`, `test.csv`. The data format is the same as event classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "32af1d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori: 6196\n",
      "new: 1191\n",
      "Done: .//n2c2_data/n2c2_data_Action/train.csv\n",
      "Done: .//n2c2_data/n2c2_data_Negation/train.csv\n",
      "Done: .//n2c2_data/n2c2_data_Temporality/train.csv\n",
      "Done: .//n2c2_data/n2c2_data_Certainty/train.csv\n",
      "Done: .//n2c2_data/n2c2_data_Actor/train.csv\n",
      "ori: 1033\n",
      "new: 221\n",
      "Done: .//n2c2_data/n2c2_data_Action/dev.csv\n",
      "Done: .//n2c2_data/n2c2_data_Negation/dev.csv\n",
      "Done: .//n2c2_data/n2c2_data_Temporality/dev.csv\n",
      "Done: .//n2c2_data/n2c2_data_Certainty/dev.csv\n",
      "Done: .//n2c2_data/n2c2_data_Actor/dev.csv\n",
      "ori: 1764\n",
      "new: 1764\n",
      "Done: .//n2c2_data/n2c2_data_Action/test.csv\n",
      "Done: .//n2c2_data/n2c2_data_Negation/test.csv\n",
      "Done: .//n2c2_data/n2c2_data_Temporality/test.csv\n",
      "Done: .//n2c2_data/n2c2_data_Certainty/test.csv\n",
      "Done: .//n2c2_data/n2c2_data_Actor/test.csv\n"
     ]
    }
   ],
   "source": [
    "!python n2c2_code/transfer_context_data.py n2c2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f470f6",
   "metadata": {},
   "source": [
    "The context classification data looks like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b951231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/280-03_T8</td>\n",
       "      <td>data. Although theoretically she should not ha...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/357-01_T1</td>\n",
       "      <td>The patient was found unconscious on the floor...</td>\n",
       "      <td>UniqueDose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/371-05_T35</td>\n",
       "      <td>weight loss and congratulated patient on recen...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/371-05_T37</td>\n",
       "      <td>w/ improvement. cont topical estradiol f/u in ...</td>\n",
       "      <td>Increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/371-05_T39</td>\n",
       "      <td>OA, b/l knee OA s/p knee replacements. Recentl...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>/378-04_T24</td>\n",
       "      <td>she was having at that time are not clear. U/A...</td>\n",
       "      <td>Stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>/289-02_T7</td>\n",
       "      <td>from Singulair. Probable mild occult gastroeso...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>/289-02_T8</td>\n",
       "      <td>mainly ocular. Prior Raynaud's syndrome. Recom...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>/289-02_T11</td>\n",
       "      <td>testing correlating well with a slight increas...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>/289-02_T12</td>\n",
       "      <td>VF arrest and revascularization. Myasthenia, m...</td>\n",
       "      <td>Start</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1191 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                                               text  \\\n",
       "0      /280-03_T8  data. Although theoretically she should not ha...   \n",
       "1      /357-01_T1  The patient was found unconscious on the floor...   \n",
       "2     /371-05_T35  weight loss and congratulated patient on recen...   \n",
       "3     /371-05_T37  w/ improvement. cont topical estradiol f/u in ...   \n",
       "4     /371-05_T39  OA, b/l knee OA s/p knee replacements. Recentl...   \n",
       "...           ...                                                ...   \n",
       "1186  /378-04_T24  she was having at that time are not clear. U/A...   \n",
       "1187   /289-02_T7  from Singulair. Probable mild occult gastroeso...   \n",
       "1188   /289-02_T8  mainly ocular. Prior Raynaud's syndrome. Recom...   \n",
       "1189  /289-02_T11  testing correlating well with a slight increas...   \n",
       "1190  /289-02_T12  VF arrest and revascularization. Myasthenia, m...   \n",
       "\n",
       "           label  \n",
       "0          Start  \n",
       "1     UniqueDose  \n",
       "2          Start  \n",
       "3       Increase  \n",
       "4          Start  \n",
       "...          ...  \n",
       "1186        Stop  \n",
       "1187       Start  \n",
       "1188       Start  \n",
       "1189       Start  \n",
       "1190       Start  \n",
       "\n",
       "[1191 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('./n2c2_data/n2c2_data_Action/train.csv', usecols=['file', 'text', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e589c5a",
   "metadata": {},
   "source": [
    "# Model training\n",
    "The next step is to use the annotated data to train the model. Here we implemented the classification model by using `transformers` provided by `Hugging Face`, a open-source Python library for transformer models. It is worth noting that the following code is for event classification. For context classification, please modify the data path in the script `n2c2_code/run_training.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d82f619c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ dir_name=n2c2_roberta\n",
      "+ model_name=roberta-base\n",
      "+ tokenizer_name=roberta-base\n",
      "+ output_path=output_n2c2_roberta\n",
      "+ log_path=log_n2c2_roberta\n",
      "+ '[' '!' -d log_n2c2_roberta ']'\n",
      "+ batch_size=32\n",
      "+ grad=1\n",
      "+ epoch=10\n",
      "+ max_seq_len=128\n",
      "+ save_steps=100\n",
      "+ train_file=train.csv\n",
      "+ dev_file=dev.csv\n",
      "+ test_file=test.csv\n",
      "+ metric=f1_micro\n",
      "+ learning_rate=2e-5\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_roberta/model_2e-5_42\n",
      "+ '[' '!' -d output_n2c2_roberta/model_2e-5_42 ']'\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_roberta/model_2e-5_62\n",
      "+ '[' '!' -d output_n2c2_roberta/model_2e-5_62 ']'\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_roberta/model_2e-5_82\n",
      "+ '[' '!' -d output_n2c2_roberta/model_2e-5_82 ']'\n",
      "+ dir_name=n2c2_biocl\n",
      "+ model_name=emilyalsentzer/Bio_ClinicalBERT\n",
      "+ tokenizer_name=emilyalsentzer/Bio_ClinicalBERT\n",
      "+ output_path=output_n2c2_biocl\n",
      "+ log_path=log_n2c2_biocl\n",
      "+ '[' '!' -d log_n2c2_biocl ']'\n",
      "+ batch_size=32\n",
      "+ grad=1\n",
      "+ epoch=10\n",
      "+ max_seq_len=128\n",
      "+ save_steps=100\n",
      "+ train_file=train.csv\n",
      "+ dev_file=dev.csv\n",
      "+ test_file=test.csv\n",
      "+ metric=f1_micro\n",
      "+ learning_rate=2e-5\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_biocl/model_2e-5_42\n",
      "+ '[' '!' -d output_n2c2_biocl/model_2e-5_42 ']'\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_biocl/model_2e-5_62\n",
      "+ '[' '!' -d output_n2c2_biocl/model_2e-5_62 ']'\n",
      "+ for i in 42 62 82\n",
      "+ data_path=n2c2_data\n",
      "+ output_dir=output_n2c2_biocl/model_2e-5_82\n",
      "+ '[' '!' -d output_n2c2_biocl/model_2e-5_82 ']'\n"
     ]
    }
   ],
   "source": [
    "# run roberta\n",
    "!sh n2c2_code/run_training.sh n2c2_roberta roberta-base roberta-base\n",
    "# run bioclinicalbert\n",
    "!sh n2c2_code/run_training.sh n2c2_biocl emilyalsentzer/Bio_ClinicalBERT emilyalsentzer/Bio_ClinicalBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf25b8",
   "metadata": {},
   "source": [
    "# Model testing/inference\n",
    "For each of `RoBERTa` and `BioClinicalBERT`, we selected the checkpoint that achieved the best performance on the dev set, and then we tested the selected checkpoint on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c2db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ batch_size=48\n",
      "+ train_file=train.csv\n",
      "+ dev_file=dev.csv\n",
      "+ test_file=test.csv\n",
      "+ data_path=n2c2_data/\n",
      "+ model_path=output_n2c2_roberta/model_2e-5_42/checkpoint-1100/\n",
      "+ tokenizer_name=output_n2c2_roberta/model_2e-5_42/checkpoint-1100/\n",
      "+ output_dir=./pred_rb\n",
      "+ max_seq_len=128\n",
      "+ metric=f1_micro\n",
      "+ '[' '!' -d ./pred_rb ']'\n",
      "+ python n2c2_code/model/run_classification.py --fp16 --max_seq_len 128 --model_name_or_path output_n2c2_roberta/model_2e-5_42/checkpoint-1100/ --config_name output_n2c2_roberta/model_2e-5_42/checkpoint-1100/ --tokenizer_name output_n2c2_roberta/model_2e-5_42/checkpoint-1100/ --task_name n2c2 --data_dir n2c2_data/ --train_file train.csv --dev_file dev.csv --test_file test.csv --custom_metric f1_micro --output_dir ./pred_rb --per_device_train_batch_size 48 --per_device_eval_batch_size 48 --overwrite_output_dir --overwrite_cache --logging_steps 1 --do_predict\n",
      "2022-11-29 12:04:57.248717: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "11/29/2022 12:05:01 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1, distributed training: False, 16-bits training: True\n",
      "11/29/2022 12:05:01 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir=./pred_rb, overwrite_output_dir=True, do_train=False, do_eval=None, do_predict=True, evaluation_strategy=IntervalStrategy.NO, prediction_loss_only=False, per_device_train_batch_size=48, per_device_eval_batch_size=48, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, lr_scheduler_type=SchedulerType.LINEAR, warmup_ratio=0.0, warmup_steps=0, logging_dir=runs/Nov29_12-05-00_rnode1.priv.bmi.emory.edu, logging_strategy=IntervalStrategy.STEPS, logging_first_step=False, logging_steps=1, save_strategy=IntervalStrategy.STEPS, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=True, fp16_opt_level=O1, fp16_backend=auto, fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=1, dataloader_num_workers=0, past_index=-1, run_name=./pred_rb, disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name=length, report_to=['tensorboard', 'wandb'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, _n_gpu=1, mp_parameters=)\n",
      "11/29/2022 12:05:01 - INFO - custom_dataset -   Load labels ['Disposition', 'NoDisposition', 'Undetermined']\n",
      "11/29/2022 12:05:01 - INFO - filelock -   Lock 139759791805328 acquired on n2c2_data/cached_train_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:01 - INFO - custom_dataset -   Creating features from dataset file at n2c2_data/\n",
      "/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/transformers/data/processors/glue.py:67: FutureWarning: This function will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING.format(\"function\"), FutureWarning)\n",
      "11/29/2022 12:05:08 - INFO - custom_dataset -   Saving features into cached file n2c2_data/cached_train_RobertaTokenizer_128_social_media [took 0.986 s]\n",
      "11/29/2022 12:05:08 - INFO - filelock -   Lock 139759791805328 released on n2c2_data/cached_train_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:08 - INFO - custom_dataset -   Load labels ['Disposition', 'NoDisposition', 'Undetermined']\n",
      "11/29/2022 12:05:08 - INFO - filelock -   Lock 139759035181432 acquired on n2c2_data/cached_dev_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:08 - INFO - custom_dataset -   Creating features from dataset file at n2c2_data/\n",
      "11/29/2022 12:05:09 - INFO - custom_dataset -   Saving features into cached file n2c2_data/cached_dev_RobertaTokenizer_128_social_media [took 0.166 s]\n",
      "11/29/2022 12:05:09 - INFO - filelock -   Lock 139759035181432 released on n2c2_data/cached_dev_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:09 - INFO - custom_dataset -   Load labels ['Disposition', 'NoDisposition', 'Undetermined']\n",
      "11/29/2022 12:05:09 - INFO - filelock -   Lock 139759453049464 acquired on n2c2_data/cached_test_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:09 - INFO - custom_dataset -   Creating features from dataset file at n2c2_data/\n",
      "11/29/2022 12:05:10 - INFO - custom_dataset -   Saving features into cached file n2c2_data/cached_test_RobertaTokenizer_128_social_media [took 0.171 s]\n",
      "11/29/2022 12:05:10 - INFO - filelock -   Lock 139759453049464 released on n2c2_data/cached_test_RobertaTokenizer_128_social_media.lock\n",
      "11/29/2022 12:05:10 - INFO - __main__ -   num labels: 3\n",
      "11/29/2022 12:05:26 - INFO - root -   *** Test ***\n",
      "11/29/2022 12:05:26 - INFO - custom_trainer -   ***** Running Prediction *****\n",
      "11/29/2022 12:05:26 - INFO - custom_trainer -     Num examples = 1033\n",
      "11/29/2022 12:05:26 - INFO - custom_trainer -     Batch size = 48\n",
      "Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:02<00:00,  9.97it/s]\n",
      "11/29/2022 12:05:29 - INFO - __main__ -   ***** Test results n2c2 *****\n",
      "11/29/2022 12:05:29 - INFO - __main__ -   ***** Test prob results n2c2 *****\n",
      "11/29/2022 12:05:29 - INFO - custom_trainer -   ***** Running Prediction *****\n",
      "11/29/2022 12:05:29 - INFO - custom_trainer -     Num examples = 1033\n",
      "11/29/2022 12:05:29 - INFO - custom_trainer -     Batch size = 48\n",
      "Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:02<00:00,  9.72it/s]\n",
      "/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:54: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "11/29/2022 12:05:31 - INFO - __main__ -   ***** Test results n2c2 *****\n",
      "11/29/2022 12:05:31 - INFO - __main__ -   ***** Test prob results n2c2 *****\n",
      "11/29/2022 12:05:31 - INFO - custom_trainer -   ***** Running Prediction *****\n",
      "11/29/2022 12:05:31 - INFO - custom_trainer -     Num examples = 6196\n",
      "11/29/2022 12:05:31 - INFO - custom_trainer -     Batch size = 48\n",
      "Prediction: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 130/130 [00:13<00:00,  9.53it/s]\n",
      "/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:36: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "/opt/rh/rh-python36/root/usr/lib/python3.6/site-packages/transformers/data/metrics/__init__.py:54: FutureWarning: This metric will be removed from the library soon, metrics should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/master/examples/text-classification/run_glue.py\n",
      "  warnings.warn(DEPRECATION_WARNING, FutureWarning)\n",
      "11/29/2022 12:05:45 - INFO - __main__ -   ***** Test results n2c2 *****\n",
      "11/29/2022 12:05:45 - INFO - __main__ -   ***** Test prob results n2c2 *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ date\r\n",
      "Tue Nov 29 12:05:46 EST 2022\r\n"
     ]
    }
   ],
   "source": [
    "# Here we run the roberta checkpoint. For bioclinicalbert, modify the model_path in the script.\n",
    "!sh n2c2_code/run_test.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b571ba81",
   "metadata": {},
   "source": [
    "The output file is named as `test_results_n2c2.txt`, which contains two columns--the indices and predictions, seperated by `\\t`. For event classification and 5 context classification subtasks (in total 6 classification tasks), the model training and testing process are the same. Finally, we can get an output file for each with the same filename. Therefore, we need to manually rename the output files into different names as below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1ead27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action.txt  Actor.txt  Certainty.txt  Event.txt  Negation.txt  Temporality.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls pred_rb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f6812",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "We evaluated the model performance by using the evaluation script provided by the shared task organizers. Because the model output file format is different from the required file format for the evaluation script, we need to reformat our output files first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5afd2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ for x in Action Actor Certainty Negation Temporality\n",
      "+ python n2c2_code/merge_id_pred.py n2c2_data/test.csv pred_rb/Action.txt pred_rb/Action_fileid.txt\n",
      "+ for x in Action Actor Certainty Negation Temporality\n",
      "+ python n2c2_code/merge_id_pred.py n2c2_data/test.csv pred_rb/Actor.txt pred_rb/Actor_fileid.txt\n",
      "+ for x in Action Actor Certainty Negation Temporality\n",
      "+ python n2c2_code/merge_id_pred.py n2c2_data/test.csv pred_rb/Certainty.txt pred_rb/Certainty_fileid.txt\n",
      "+ for x in Action Actor Certainty Negation Temporality\n",
      "+ python n2c2_code/merge_id_pred.py n2c2_data/test.csv pred_rb/Negation.txt pred_rb/Negation_fileid.txt\n",
      "+ for x in Action Actor Certainty Negation Temporality\n",
      "+ python n2c2_code/merge_id_pred.py n2c2_data/test.csv pred_rb/Temporality.txt pred_rb/Temporality_fileid.txt\n",
      "+ python n2c2_code/reformat_results_e2e.py n2c2_data/raw/test n2c2_data/test.csv pred_rb pred_rb_final\n",
      "Done! output is pred_rb_final\n"
     ]
    }
   ],
   "source": [
    "# reformat our output and store the reformated output file in `pred_rb_final`\n",
    "!sh n2c2_code/reformat_results.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5924a373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files skipped in /home/yguo262/n2c2_2022_classification/n2c2_data/raw/test_gold:\n",
      "169-02.ann, 186-04.ann\n",
      "\n",
      "******************** Evaluation n2c2 2022 Track 1 ********************\n",
      "************* Contextualized Medication Event Extraction *************\n",
      "\n",
      "*********************** Medication Extraction ************************\n",
      "                      ------- strict -------    ------ lenient -------\n",
      "                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n",
      "                Drug  1.0000  1.0000  1.0000    1.0000  1.0000  1.0000\n",
      "\n",
      "\n",
      "************************ Event Classification ************************\n",
      "                      ------- strict -------    ------ lenient -------\n",
      "                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n",
      "         Disposition  0.2036  0.2145  0.2089    0.2036  0.2145  0.2089\n",
      "       Nodisposition  0.7517  0.7511  0.7514    0.7517  0.7511  0.7514\n",
      "        Undetermined  0.0381  0.0328  0.0352    0.0381  0.0328  0.0352\n",
      "                      ------------------------------------------------\n",
      "     Overall (micro)  0.6054  0.6051  0.6053    0.6054  0.6051  0.6053\n",
      "     Overall (macro)  0.3311  0.3328  0.3319    0.3311  0.3328  0.3319\n",
      "\n",
      "\n",
      "*********************** Context Classification ***********************\n",
      "                      ------- strict -------    ------ lenient -------\n",
      "                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n",
      "              Action  0.0838  0.0836  0.0837    0.0838  0.0836  0.0837\n",
      "         Temporality  0.1048  0.1045  0.1046    0.1048  0.1045  0.1046\n",
      "           Certainty  0.1437  0.1433  0.1435    0.1437  0.1433  0.1435\n",
      "               Actor  0.1976  0.1970  0.1973    0.1976  0.1970  0.1973\n",
      "            Negation  0.2036  0.2030  0.2033    0.2036  0.2030  0.2033\n",
      "                      ------------------------------------------------\n",
      "     Overall (micro)  0.1467  0.1463  0.1465    0.1467  0.1463  0.1465\n",
      "     Overall (macro)  0.1467  0.1463  0.1465    0.1467  0.1463  0.1465\n",
      "\n",
      "\n",
      "                      ------- strict -------    ------ lenient -------\n",
      "                      Prec.   Rec.    F(b=1)    Prec.   Rec.    F(b=1)\n",
      "            Combined  0.0359  0.0358  0.0359    0.0359  0.0358  0.0359\n",
      "\n",
      "\n",
      "                                   98 files evaluated               \n"
     ]
    }
   ],
   "source": [
    "# run the evaluation script\n",
    "!python n2c2_code/eval_script.py n2c2_data/raw/test_gold pred_rb_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
